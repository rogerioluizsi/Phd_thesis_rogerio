
% resumo em português
\begin{resumo}[Resumo] 
Esta tese investiga a aplicação de Inteligência Artificial Explicável (IAE) em modelos de Aprendizagem de Máquina Supervisionada (AMS). A motivação para esse estudo decorre do desenvolvimento da Mineração de Dados Educacionais (MDE), uma área de estudo que frequentemente emprega tais modelos para analisar e extrair conhecimentos de vastos conjuntos de dados. Um aspecto central dessa tese é o desafio de gerar explicações globais para AMS, particularmente em situações onde a independência entre os dados não é garantida. Esta é uma problemática recorrente, mas ainda pouco explorada na MDE. A negligência das interdependências entre os dados pode levar a explicações enviesadas, valorização excessiva de variáveis irrelevantes ou atribuição desproporcional de importância a preditores de similar relevância. Para resolver estes desafios, a tese baseia-se em um método recente para a visualização do impacto das variáveis em modelos supervisionados, conhecido em inglês como Accumulated Local Effects (ALE), que se refere à distribuição acumulada de efeitos locais. A propriedade pseudo-ortogonal de ALE permite isolar os efeitos de variáveis individualmente, distinguindo-a de métodos amplamente usados em MDE, como os gráficos de dependência parcial e explicações baseadas  em valores de Shapley. Em uma etapa inicial, as técnicas ALE são comparadas a outras existentes utilizando uma nova metodologia que avalia quão bem essas técnicas se aproximam do efeito real das variáveis nos modelos em vários contextos de dependência de dados. Além disso, com base nos resultados promissores dessa etapa, este trabalho propõe novos escores baseados em ALE para medir o impacto das variáveis em modelos de AMS. Esses escores são agnósticos a modelos e podem capturar tanto a magnitude quanto a direção do impacto individual das variáveis. Os escores demonstram eficiência em vários cenários quando comparados com as métricas existentes em conjuntos de dados sintéticos e reais. Além disso, um estudo empírico utilizando os dados das escolas secundárias brasileiras não apenas ratifica a utilidade dos novos escores em um cenário do mundo real, mas também estende as contribuições desta tese ao identificar e oferecer novas perspectivas sobre os determinantes do sucesso escolar brasileiro ao longo de mais de uma década.

% \noindent %- o resumo deve ter apenas 1 parágrafo e sem recuo de texto na primeira linha, essa tag remove o recuo. Não pode haver quebra de linha.

 \vspace{\onelineskip}
    
 \noindent
 \textbf{Palavras-chaves}: IA explicável. Aprendizagem de máquina interpretável.  Explicadores globais. Mineração de dados educacionais. Importância de variáveis. ALE.
\end{resumo}

%resumo em inglês
\begin{resumo}[Abstract]
\begin{otherlanguage*}{english}

 %\noindent
This thesis investigates the application of Explainable Artificial Intelligence (XAI) in Supervised Machine Learning (SML) models. The motivation for this study stems from the development of Educational Data Mining (EDM), an area that frequently uses such models to analyze and extract insights from large datasets. A central issue of this work is the challenge of generating global explanations for SML, particularly in cases where data independence is not guaranteed. This is a recurring but still underexplored problem in EDM. Neglecting data interdependencies can lead to biased explanations, overestimating irrelevant variables or disproportionately assigning importance to predictors with similar relevance. To address these challenges, this work builds on Accumulated Local Effects (ALE), a recent method for post-hoc global explanation that visualizes the impact of features. ALE’s pseudo-orthogonality property allows for isolating individual variable effects, distinguishing it from widely used methods in EDM such as partial dependence plots and Shapley-based explanations. In a preliminary stage, ALE techniques is compared to other existing ones by using a new methodology that evaluates how different these techniques approximate the true variable effects in various contexts of data dependency. In a preliminary stage, ALE techniques are compared to other existing ones using a new methodology that evaluates how well these techniques approximate the true variable effects in various contexts of data dependency. Furthermore, based on the ALE promising results of this stage, this work proposes new ALE-based scores to measure the impact of variables in SML. The scores are model-agnostic and can report both the magnitude and direction of the individual impact of features. The scores prove to be efficient in various scenarios when compared to existing metrics on synthetic and real-world datasets. Moreover, an empirical study using data from Brazilian secondary schools not only confirms the usefulness of the new scores in a real-world scenario but also extends the contributions of this thesis by identifying and offering new perspectives on the determinants of Brazilian school success over more than a decade.

\vspace{\onelineskip} 

\noindent 
\textbf{Keywords}: Explaineble AI. Interpretable ML.  Global explainers. EDM. Feature importance. ALE.
\end{otherlanguage*}
\end{resumo}
